\newcommand{\orgmode}{\texttt{org-mode}}
\newcommand{\Makefile}{\mintinline{shell}{Makefile}}
\newcommand{\context}{\mintinline{shell}{context}}
\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf +}}
\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}

\section{Introduction}

\subsection{Summary of report D1.1}

\Ac{QMCkl} aims at providing a high-performance
implementation of the main kernels of \ac{QMC} methods. 
\ac{WP}~1 focuses on defining the \ac{API}, the tests,
and a \emph{pedagogical} presentation of the main algorithms.
In \ac{WP}~3, the \ac{HPC} experts use this repository as a reference for re-writing
optimized versions of the functions proposed in this pedagogical version of the library.

To maximize the portability to unknown architectures, we have chosen to provide an \ac{API} which
is compatible with the C programming language. The foundations of the library are written in C, but Fortran
was chosen to express the kernels as it is more convenient than C for expressing linear algebra.
The dependencies to external software are kept minimal to facilitate the installation, and the
BSD 3-clause license was chosen to facilitate the adoption of the library by industrial 
collaborators.

As this version version of the library is intended to be mostly used as documentation, 
we chose to use literate programming\cite{knuth_1992} in {\orgmode}
format.\cite{schulte_2012,orgmode} The documentation
is first written, and the code illustrates the documentation. From the same source files,
the documentation is generated both in text and HTML formats, as well as the C code of the library.
This practice helps the documentation to always be consistent with the code.

The documentation of the current status of the library is available
at \url{https://trex-coe.github.io/qmckl}, and the source code is
available on the GitHub repository at \url{https://github.com/trex-coe/qmckl}.

\subsection{QMCkl's objective}

\newcommand{\Nelec}{N_{\text{elec}}}
\newcommand{\Nelecup}{N_{\text{elec}}^\uparrow}
\newcommand{\Nelecdn}{N_{\text{elec}}^\downarrow}
\newcommand{\br}{\mathbf{r}_1,\dots,\mathbf{r}_{\Nelec}}
\newcommand{\brup}{\mathbf{r}_1,\dots,\mathbf{r}_{\Nelec^\uparrow}}
\newcommand{\brdn}{\mathbf{r}_{\Nelec^\uparrow+1},\dots,\mathbf{r}_{\Nelec}}

The most common form of wave function used in \ac{QMC} simulations is
expressed as a linear combination of Slater determinants $D_I$ multiplied by
a Jastrow correlation factor $\exp(J)$:
\begin{equation}
  \Psi(\br) = \left( \sum_I c_I\, D_I(\br) \right) \exp \left( J(\br) \right).
\end{equation}

The Jastrow factor is a positive function of electron-electron,
electron-nucleus and electron-electron-nucleus distances. 

The Slater determinants are expressed as products of $\uparrow$-spin
$\downarrow$-spin determinants:
\begin{eqnarray}
D_I(\br) = D_i^\uparrow(\brup)\, D_j^\downarrow(\brdn),
\end{eqnarray}
where $\Nelec = \Nelecup + \Nelecdn$ is the number of
electrons, the sum of of the numbers of up- and down-spin electrons.

The determinants are built in a basis of \acp{MO},
\begin{equation}
  D_i^\uparrow(\brup) = \left|
    \begin{array}{ccc}
      \phi_{i(1)}(\mathbf{r}_1) & \dots & \phi_{i(\Nelecup)}(\mathbf{r}_1) \\
        \vdots & \ddots & \vdots \\
      \phi_{i(1)}(\mathbf{r}_{\Nelecup}) & \dots & \phi_{i(\Nelecup)}(\mathbf{r}_{\Nelecup}) 
    \end{array}
    \right|
\end{equation}
and each determinant differs from the other ones by the indices $\{
i(1), \dots, i(\Nelecup) \}$ of the \acp{MO} composing it.

The \acp{MO} $\phi$ are linear combinations of \acp{AO} $\chi$:
\begin{equation}
\phi_j(\mathbf{r}) = \sum_k C_{kj} \chi_k(\mathbf{r}),
\end{equation}
each \ac{AO} being a function centered on a nucleus with a radial and an angular part.
The angular part is expressed whether as spherical harmonics $Y_{lm}$ or as a polynomial, and
the angular part is generally a linear combination of Gaussian functions:
\begin{equation}
\chi_k(\mathbf{r}) = (x-X_A)^a (y-Y_A)^b (z-Z_A)^c \sum_l d_l\, \exp \left(
    -\gamma_{kl} |\mathbf{r}-\mathbf{R}_A|^2 \right)
\end{equation}
where $\mathbf{r} = (x,y,z)$ is an electron coordinate and 
$\mathbf{R_A} = (X_A,Y_A,Z_A)$ is the coordinate of nucleus $A$.

At each step of the \ac{QMC} simulation, the wave function needs to be
evaluated at the electron positions. The dynamics of the electrons
requires also the gradient of the wave function with respect to electron
coordinates, and the computation of the kinetic energy needs the Laplacian
of the wave function.

The quantities involved in the calculation of the wave function are the most
important kernels to be implemented in QMCkl, because they represent the main
computational bottleneck of \ac{QMC} simulations.


\section{Work done since D1.1}

\subsection{New functionalities}

\subsubsection{Implemented kernels}
%    AOs VGL
%    MOs VGL
%    AOs values
%    MOs values
%    Integration of Jastrow
%    Finished Shermann-Morrison-Woodbury implementation
%    Jastrow mu?

\subsubsection{Improvement of design}
%    In-place functions
%    Added notion of point instead of electron


\subsubsection{Python interface}
% Modification of API to simplify Python binding
% Tested for GNU, Intel, Nvidia, IBM compilers
% Integration of TREXIO
% AddressSanitizer


\subsection{Documentation}
% Examples.org
% Installation instructions
% Tutorials

\subsection{Building the library}

\subsubsection{Autotools}
%    Removed munit
%    Out of source builds
%    Facilitates packaging (.deb for trexio)
%    --disable-doc

\subsubsection{Packaging}
% Package for Spack, not upstream yet
% FindQMCKL module for CMake
% Guix packaging
% PIP packaging
% Possibility to link with QMCKL_dgemm

\subsection{Usage of QMCkl in external software}
%    Adoption in TREXIO tools
%    Possible collaboration with industry => DFT code

\subsubsection{Feedback from HPC experts}
%   Data structures for HPC
%   QMCkl dgemm => BLAS

\subsubsection{Feedback from users}
%   Edgar and fixed number of points
%   Restructuring from GPU version
%   PoC: integration in CHAMP
%   PoC: integration in TurboRVB

